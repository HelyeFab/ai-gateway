version: '3'

services:
  # Use llama.cpp with Stable Diffusion support
  sd-api:
    image: ghcr.io/abetlen/llama-cpp-python:latest
    container_name: ai-gateway-sd-api
    ports:
      - "7860:8000"
    environment:
      - MODEL=/models/stable-diffusion-v1-4.ggml
    volumes:
      - ./stable-diffusion-simple:/app
      - ./data/models:/models
    command: python /app/server.py
    restart: unless-stopped
    networks:
      - ai-gateway_default

  # OpenAI Whisper API
  whisper-api:
    image: ahmetoner/whisper-asr-webservice:latest-gpu
    container_name: ai-gateway-whisper
    ports:
      - "8092:9000"
    environment:
      - ASR_MODEL=base
      - ASR_ENGINE=openai_whisper
    restart: unless-stopped
    networks:
      - ai-gateway_default

networks:
  ai-gateway_default:
    external: true